{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#model parameters\n",
    "convWidth = 5\n",
    "conv1feat = 64\n",
    "conv2feat = 64\n",
    "conv3feat = 64\n",
    "linear1feat = 32\n",
    "\n",
    "\n",
    "\n",
    "def weight_variable(shape, sd=0.0001):\n",
    "    initial = tf.truncated_normal(shape, sd)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, value=0.0001):\n",
    "    initial = tf.constant(value, shape=shape, dtype=tf.float32)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "class model:\n",
    "    def __init__(self, imagesIn, labelsTru):\n",
    "        \n",
    "        # get dimensions\n",
    "        dimIn = int(images.get_shape()[1])\n",
    "        classes = int(labelsTru.get_shape()[1])\n",
    "        \n",
    "        self.images = imagesIn\n",
    "        \n",
    "        # define graph variables\n",
    "        Wconv1 = weight_variable([convWidth, convWidth, 3, conv1feat], 0.0001) \n",
    "        bConv1 = bias_variable([conv1feat])\n",
    "        Wconv2 = weight_variable([convWidth, convWidth, conv1feat, conv2feat], 0.01) \n",
    "        bConv2 = bias_variable([conv2feat])\n",
    "        Wconv3 = weight_variable([convWidth, convWidth, conv2feat, conv3feat], 0.01) \n",
    "        bConv3 = bias_variable([conv3feat])\n",
    "        dim3 = dimIn /2 /2 \n",
    "        Wfc1 = weight_variable([dim3 * dim3 * conv3feat, linear1feat], 0.1) \n",
    "        bFC1 = bias_variable([linear1feat])\n",
    "        Wfc2 = weight_variable([linear1feat, classes], 0.1)\n",
    "        bFC2 = bias_variable([classes])\n",
    "        \n",
    "        # convolution 1, with batch-norm and pooling\n",
    "        hConv1pre = conv2d(imagesIn, Wconv1) + bConv1\n",
    "        hConv1n = tf.contrib.layers.batch_norm(hConv1pre, center=True, scale=True)\n",
    "        hConv1n = tf.nn.relu(hConv1n)\n",
    "        # hConv1n = tf.nn.dropout(hConv1n,1-hiddenDropRate)\n",
    "        hPool1 = max_pool(hConv1n)\n",
    "        # hPool1 = hConv1\n",
    "\n",
    "        # convolution 2, with batch-norm and no pooling\n",
    "        hConv2pre = conv2d(hPool1, Wconv2) + bConv2\n",
    "        hConv2n = tf.contrib.layers.batch_norm(hConv2pre, center=True, scale=True)\n",
    "        hConv2n = tf.nn.relu(hConv2n)\n",
    "        # hConv2n = tf.nn.dropout(hConv2n, 1-hiddenDropRate)\n",
    "        # hPool2 = max_pool(hConv2n)\n",
    "        hPool2 = hConv2n\n",
    "\n",
    "        # convolution3 with skip connection to output from conv1, followed by pooling\n",
    "        hConv3pre = conv2d(hPool2, Wconv3) + bConv3 + hPool1\n",
    "        hConv3n = tf.contrib.layers.batch_norm(hConv3pre, center=True, scale=True)\n",
    "        hConv3n = tf.nn.relu(hConv3n)\n",
    "        hPool3 = max_pool(hConv3n)\n",
    "\n",
    "        # non-linear layer 1, flatten processed image into vector; transform and apply batch norm and relu\n",
    "        hPool2flat = tf.reshape(hPool3, [-1,dim*dim*conv2feat])\n",
    "        hFC1pre = tf.matmul(hPool2flat, Wfc1) + bFC1\n",
    "        hFC1n = tf.contrib.layers.batch_norm(hFC1pre, center=True, scale=True)\n",
    "        hFC1n = tf.nn.relu(hFC1n)\n",
    "\n",
    "        # readout layer, softmax means elements of y form probability distribution (sum to one)\n",
    "        self.labels = tf.nn.softmax(tf.matmul(hFC1n, Wfc2) + bFC2)\n",
    "        \n",
    "        # calculate cross entropy between predictions and ground truth\n",
    "        self.crossEntropy = tf.reduce_mean(-tf.reduce_sum(labelsTru * tf.log(self.y), reduction_indices=[1]))\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.y, 1), tf.argmax(labelsTru, 1))\n",
    "        \n",
    "        # correct_prediction gives list of booleans, take mean to measure % accuracy\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    def use_nesterov(self, eta=0.1, gamma=0.9):\n",
    "        # set training method\n",
    "        self.trainStep = tf.train.MomentumOptimizer(eta, gamma, use_nesterov=True).minimize(self.crossEntropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADSNUu0bseoCKuxuI5ZeTl1a/Img?dl=0&preview=img_align_celeba.zip\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
